# -*- coding: utf-8 -*-
"""appp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18EVIpNy_3DYdSjvjTM4NkcqiLdX5JKIJ
"""

pip install virtualenv

pip install streamlit

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
import pickle
import streamlit as st
from sklearn.preprocessing import LabelEncoder
from pickle import load

loaded_model = pickle.load(open("Bigmart_Project.sav","rb"))





# Loading the training data for label encoding
data_train = pd.read_csv("Train.csv")

# Label encoding for all categorical columns
label_encoders = {}
categorical_columns = ["Item_Fat_Content", "Outlet_Size", "Outlet_Location_Type",
                        "Item_Fat_Content", "Item_Identifier", "Outlet_Identifier",
                        "Item_Type", "Outlet_Type"]

for column in categorical_columns:
    le = LabelEncoder()
    data_train[column] = le.fit_transform(data_train[column])
    label_encoders[column] = le

# Splitting into train and test
from sklearn.model_selection import train_test_split
y = data_train["Item_Outlet_Sales"]
x = data_train.drop("Item_Outlet_Sales", axis=1)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=0)

# Standardize the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train_std = sc.fit_transform(x_train)

def preprocess_user_input(item_weight, item_fat_content, item_visibility, item_type, item_mrp,
                          outlet_establishment_year, outlet_size, outlet_location_type, outlet_type):
    # Encode categorical features
    item_fat_content = label_encoders['Item_Fat_Content'].transform([item_fat_content])[0]
    outlet_size = label_encoders['Outlet_Size'].transform([outlet_size])[0]
    outlet_location_type = label_encoders['Outlet_Location_Type'].transform([outlet_location_type])[0]
    item_identifier = label_encoders['Item_Identifier'].transform([item_identifier])[0]
    outlet_identifier = label_encoders['Outlet_Identifier'].transform([outlet_identifier])[0]
    item_type = label_encoders['Item_Type'].transform([item_type])[0]
    outlet_type = label_encoders['Outlet_Type'].transform([outlet_type])[0]

    # Converting to float
    inputs = [float(item_weight), item_fat_content, float(item_visibility), item_type,
              float(item_mrp), float(outlet_establishment_year), outlet_size,
              outlet_location_type, outlet_type]

    # Standardizing the input
    inputs_std = sc.transform([inputs])

    return inputs_std

def Bigmart_Prediction(X_test_std):
    y_pred_lr = loaded_model(x_test_std)
    return y_pred_lr

def main():
    # Title
    st.title('BigMart Sales prediction')

    # User inputs
    item_weight = st.text_input('Item Weight')
    item_fat_content = st.selectbox('Item Fat Content', data_train['Item_Fat_Content'].unique())
    item_visibility = st.text_input('Item Visibility')
    item_type = st.selectbox('Item Type', data_train['Item_Type'].unique())
    item_mrp = st.text_input('Item MRP')
    outlet_establishment_year = st.text_input('Outlet Establishment Year')
    outlet_size = st.selectbox('Outlet Size', data_train['Outlet_Size'].unique())
    outlet_location_type = st.selectbox('Outlet Location Type', data_train['Outlet_Location_Type'].unique())
    outlet_type = st.selectbox('Outlet Type', data_train['Outlet_Type'].unique())

    Prediction = ' '

    if st.button('Predict'):
        user_inputs_std = preprocess_user_input(item_weight, item_fat_content, item_visibility,
                                                item_type, item_mrp, outlet_establishment_year,
                                                outlet_size, outlet_location_type, outlet_type)
        Prediction = Bigmart_Prediction(user_inputs_std)
        st.success(f'Predicted Sales: {Prediction[0]:.2f}')

if __name__ == "__main__":
    main()



